{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c5cff8-9db9-4906-89fd-f550dc249517",
   "metadata": {},
   "source": [
    "# Optimizing BERT for Fast Inference with NVIDIA TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696bbdcb-c92a-4f10-a2d0-24b6ec342816",
   "metadata": {},
   "source": [
    "This notebook uses the `transformer-deploy` library to facilitate `Nvidia TensorRT` INT8 quantization and optimization of BERT that was fine-tuned with a custom implementation in the notebook `fine-tuning.ipynb`.\n",
    "\n",
    "Modified from the transformer-deploy end-to-end walkthrough: https://github.com/ELS-RD/transformer-deploy/blob/main/demo/quantization/quantization_end_to_end.ipynb\n",
    "\n",
    "Transformer-deploy documentation: https://els-rd.github.io/transformer-deploy/quantization/quantization_intro/.\n",
    "\n",
    "Transformer-deploy Github: https://github.com/ELS-RD/transformer-deploy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3777bbe9-804c-451d-aedb-48e0bfbf8aab",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8987c-29e8-47ec-a015-9cd665de8596",
   "metadata": {},
   "source": [
    "To run this notebook, your system must have `Nvidia CUDA 11.X`, `TensorRT 8.2.1`, and `cuBLAS` installed.\n",
    "\n",
    "To ensure that all dependencies are correctly installed and that the code runs as expected, it is suggested to use the below Docker image, which can be pulled with the below command in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2863ca04-2bde-44a0-9517-ea17b0239e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T17:15:28.465702Z",
     "iopub.status.busy": "2023-07-25T17:15:28.465034Z",
     "iopub.status.idle": "2023-07-25T17:15:28.468785Z",
     "shell.execute_reply": "2023-07-25T17:15:28.468074Z",
     "shell.execute_reply.started": "2023-07-25T17:15:28.465670Z"
    }
   },
   "outputs": [],
   "source": [
    "# docker pull ghcr.io/els-rd/transformer-deploy:0.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbcd20e-6d77-425a-9332-f4dbca2f442e",
   "metadata": {},
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6120dc22-ca75-4c38-b92f-a4e13a55a3b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T17:01:33.804480Z",
     "iopub.status.busy": "2023-07-25T17:01:33.803903Z",
     "iopub.status.idle": "2023-07-25T17:01:33.807736Z",
     "shell.execute_reply": "2023-07-25T17:01:33.807015Z",
     "shell.execute_reply.started": "2023-07-25T17:01:33.804454Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/ELS-RD/transformer-deploy.git\n",
    "# !pip install numpy==1.23.5\n",
    "# !pip install pandas\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02efd6-7315-426d-8bfb-80656020433f",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6eebb8-1bea-43ca-9661-8e20307d859a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T18:40:56.452204Z",
     "iopub.status.busy": "2023-07-25T18:40:56.451434Z",
     "iopub.status.idle": "2023-07-25T18:40:56.456889Z",
     "shell.execute_reply": "2023-07-25T18:40:56.456334Z",
     "shell.execute_reply.started": "2023-07-25T18:40:56.452188Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union\n",
    "from typing import OrderedDict as OD\n",
    "\n",
    "# third party imports\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "import tqdm\n",
    "import transformers\n",
    "from datasets import Dataset, load_dataset, load_metric\n",
    "from tensorrt.tensorrt import IExecutionContext, Logger, Runtime\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    IntervalStrategy,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    ")\n",
    "\n",
    "# local library specific imports\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from transformer_deploy.QDQModels.calibration_utils import QATCalibrate\n",
    "from transformer_deploy.backends.ort_utils import (\n",
    "    cpu_quantization,\n",
    "    create_model_for_provider,\n",
    "    optimize_onnx,\n",
    ")\n",
    "from transformer_deploy.backends.pytorch_utils import convert_to_onnx\n",
    "from transformer_deploy.backends.trt_utils import (\n",
    "    build_engine,\n",
    "    get_binding_idxs,\n",
    "    infer_tensorrt,\n",
    "    load_engine,\n",
    "    save_engine,\n",
    ")\n",
    "from transformer_deploy.benchmarks.utils import print_timings, track_infer_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7fbf8-5357-4245-b3bb-3f51570e3963",
   "metadata": {},
   "source": [
    "Check that numpy version 1.23.5 is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2275298e-c255-4415-8643-c1ae8ac7da7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T17:17:32.483059Z",
     "iopub.status.busy": "2023-07-25T17:17:32.482443Z",
     "iopub.status.idle": "2023-07-25T17:17:32.486460Z",
     "shell.execute_reply": "2023-07-25T17:17:32.485828Z",
     "shell.execute_reply.started": "2023-07-25T17:17:32.483033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.5\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)  # make sure numpy version is 1.23.5, otherwise install\n",
    "\n",
    "# !pip install numpy==1.23.5  # run this line if not numpy version 1.23.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9320cd-0acd-47ec-a593-5db9aec8a1d1",
   "metadata": {},
   "source": [
    "### STEP 1: Convert Fine-Tuned Model to Hugging Face Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f62e37-8b95-45c0-812d-35c2dee163f7",
   "metadata": {},
   "source": [
    "\n",
    "In `fine-tune.py` we saved the PyTorch state dictionary of our fine-tuned custom implementations of BERT in the `models/` directory. \n",
    "\n",
    "We will use Hugging Face's implementation of BERT moving forward in this notebook.\n",
    "\n",
    "To do so we need to convert the state dictionary (ex. `bert_base_epoch_1.pt`) to a serielized Hugging Face format that will include a `config.json` and `pytorch_model.bin` file ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c139aa-734b-47a4-904b-e119cb5a986f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T18:41:02.742157Z",
     "iopub.status.busy": "2023-07-25T18:41:02.741521Z",
     "iopub.status.idle": "2023-07-25T18:41:05.472540Z",
     "shell.execute_reply": "2023-07-25T18:41:05.471675Z",
     "shell.execute_reply.started": "2023-07-25T18:41:02.742130Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained BERT-base model\n",
    "bert_base_fine_tuned = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# assign to variable the state dictionary of fine-tuned model from fine-tune.py that you want to quantize\n",
    "state_dict = torch.load(\"../models/bert_base_fine_tuned/bert_base_epoch_1.pt\")\n",
    "\n",
    "# load the fine-tuned weights from the state dictionary into the base model\n",
    "bert_base_fine_tuned.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "\n",
    "# create directory and filepaths to download into serielized Hugging Face format\n",
    "dir_path = Path(\"../models/model_hugging_face\")\n",
    "dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save model in serielized Hugging Face format\n",
    "bert_base_fine_tuned.save_pretrained(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b6aac-7a5b-4356-810c-331b8165a698",
   "metadata": {},
   "source": [
    "### STEP 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8ed92-a4f8-4819-96b5-f6edcd09162a",
   "metadata": {},
   "source": [
    "Set logging to error level for readability in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a6db9d7-c283-4209-a729-78f998a48ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T18:42:03.488536Z",
     "iopub.status.busy": "2023-07-25T18:42:03.487985Z",
     "iopub.status.idle": "2023-07-25T18:42:04.297571Z",
     "shell.execute_reply": "2023-07-25T18:42:04.296879Z",
     "shell.execute_reply.started": "2023-07-25T18:42:03.488511Z"
    }
   },
   "outputs": [],
   "source": [
    "log_level = logging.ERROR\n",
    "logging.getLogger().setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "trt_logger: Logger = trt.Logger(trt.Logger.ERROR)\n",
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab56ec85-4f42-42c8-b107-6edeebbc9802",
   "metadata": {},
   "source": [
    "Set directories and other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b4c970b-6628-4187-bcc7-6a4a8401c10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T18:42:05.667777Z",
     "iopub.status.busy": "2023-07-25T18:42:05.667114Z",
     "iopub.status.idle": "2023-07-25T18:42:05.672848Z",
     "shell.execute_reply": "2023-07-25T18:42:05.672154Z",
     "shell.execute_reply.started": "2023-07-25T18:42:05.667752Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = \"../models/model_hugging_face\"  # directory to the serielized hugging face model we are optimizing/quantizing\n",
    "model_quantized_dir = \"../models/model_quantized\"  # directory to save the model after quantized aware training\n",
    "num_labels = 2 \n",
    "batch_size = 32\n",
    "max_seq_len = 512\n",
    "timings: Dict[str, List[float]] = dict()\n",
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "profile_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe1e2bb-0e5d-457e-ab43-6a561befd9ac",
   "metadata": {},
   "source": [
    "Preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b900ca-2fb0-4299-ae77-eeacb29f6928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T03:55:25.551494Z",
     "iopub.status.busy": "2023-07-25T03:55:25.550927Z",
     "iopub.status.idle": "2023-07-25T03:56:23.049087Z",
     "shell.execute_reply": "2023-07-25T03:56:23.048404Z",
     "shell.execute_reply.started": "2023-07-25T03:55:25.551468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce636d0a03d041d888381d1e335b2cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/112217 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23e4070419f403ab6676c56cf7a16a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80d519f24ca46a985bb3548f81ed590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdce44ca1d754cddb24484b235311cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea78044e03c94246ada8553409e8ec86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a13c3791d58446985bdc54aab95bd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a020d3c10d4f45579525e5598fa759db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2367efb9e4d4994933fd13aea841f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/112217 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7254df25f64b8f977da90d99f79e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcef8567ee341dabed9544dab9e1931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train-sample.csv\")\n",
    "\n",
    "# dict mapping strings to integers\n",
    "string_to_int = {\n",
    "    'open': 0,\n",
    "    'not a real question': 1,\n",
    "    'off topic': 1,\n",
    "    'not constructive': 1,\n",
    "    'too localized': 1\n",
    "}\n",
    "\n",
    "# add new features to dataframe\n",
    "df['OpenStatusInt'] = df['OpenStatus'].map(string_to_int)  # convert class strings to integers\n",
    "df['BodyLength'] = df['BodyMarkdown'].apply(lambda x: len(x.split(\" \")))  # number of words in body text\n",
    "df['TitleLength'] = df['Title'].apply(lambda x: len(x.split(\" \")))  # number of words in title text\n",
    "df['TitleConcatWithBody'] = df.apply(lambda x: x.Title +  \" \" + x.BodyMarkdown, axis=1)  # combine title and body text\n",
    "df['NumberOfTags'] = df.apply(\n",
    "    lambda x: len([x[col] for col in ['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5'] if not pd.isna(x[col])]), \n",
    "    axis=1,\n",
    ")  # number of tags\n",
    "\n",
    "# list of col names with tabular data \n",
    "tabular_feature_list = [\n",
    "    'ReputationAtPostCreation',  \n",
    "    'BodyLength', \n",
    "    'TitleLength', \n",
    "    'NumberOfTags',\n",
    "]\n",
    "\n",
    "# place the desired data from the dataframe into a dictionary\n",
    "data_dict = {\n",
    "    'text': df.TitleConcatWithBody.tolist(),\n",
    "    'tabular': df[tabular_feature_list].values,\n",
    "    'label': df.OpenStatusInt.tolist(),\n",
    "}\n",
    "\n",
    "# load data into hugging face dataset object\n",
    "dataset_stackoverflow = Dataset.from_dict(data_dict)\n",
    "\n",
    "# define the indices at which to split the dataset\n",
    "n_samples = len(dataset_stackoverflow)\n",
    "split_idx1 = int(n_samples * 0.8)\n",
    "split_idx2 = int(n_samples * 0.9)\n",
    "\n",
    "# shuffle the dataset\n",
    "shuffled_dataset = dataset_stackoverflow.shuffle(seed=42)\n",
    "\n",
    "# split dataset training/validation/test\n",
    "train_dataset = shuffled_dataset.select(range(split_idx1))\n",
    "val_dataset = shuffled_dataset.select(range(split_idx1, split_idx2))\n",
    "test_dataset = shuffled_dataset.select(range(split_idx2, n_samples))\n",
    "\n",
    "# calculate mean and std of each tabular feature\n",
    "mean_train = torch.mean(torch.tensor(train_dataset['tabular'], dtype=torch.float32), dim=0)\n",
    "std_train = torch.std(torch.tensor(train_dataset['tabular'], dtype=torch.float32), dim=0)\n",
    "\n",
    "# define a function to apply standard scaling to the tabular data\n",
    "def standard_scale(example):\n",
    "    example['tabular'] = (torch.tensor(example['tabular']) - mean_train) / std_train\n",
    "    return example\n",
    "\n",
    "# apply the standard scaling function to the tabular features\n",
    "train_dataset = train_dataset.map(standard_scale)\n",
    "val_dataset = val_dataset.map(standard_scale)\n",
    "test_dataset = test_dataset.map(standard_scale)\n",
    "\n",
    "# instantiate tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", max_length=512, truncation=True)\n",
    "\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb27a33-93f2-407a-9cb7-c421816631ae",
   "metadata": {},
   "source": [
    "Helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bc897-2918-42ad-8c4c-0c9697cd2d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T04:08:12.489648Z",
     "iopub.status.busy": "2023-07-25T04:08:12.488957Z",
     "iopub.status.idle": "2023-07-25T04:08:12.497038Z",
     "shell.execute_reply": "2023-07-25T04:08:12.496505Z",
     "shell.execute_reply.started": "2023-07-25T04:08:12.489627Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\" Function to compute evaluation metrics for Hugging Face's Trainer. \"\"\"\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\" Function to drop unnecessary tensors from the logits that can consume memory. \"\"\"\n",
    "    \n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "    \n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "def get_trainer(model):\n",
    "    \"\"\" Function that instantiates and returns a Hugging Face Trainer.  \"\"\"\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_tokenized,\n",
    "        eval_dataset=test_tokenized,\n",
    "        tokenizer=tokenizer,\n",
    "        preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    transformers.logging.set_verbosity_error()\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "\n",
    "def convert_tensor(data: OD[str, List[List[int]]], output: str) -> OD[str, Union[np.ndarray, torch.Tensor]]:\n",
    "    \"\"\" Function to convert list inputs into either tensor or numpy array format. \"\"\"\n",
    "    \n",
    "    input: OD[str, Union[np.ndarray, torch.Tensor]] = OrderedDict()\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]:\n",
    "        if k in data:\n",
    "            v = data[k]\n",
    "            if output == \"torch\":\n",
    "                value = torch.tensor(v, dtype=torch.long, device=\"cuda\")\n",
    "            elif output == \"np\":\n",
    "                value = np.asarray(v, dtype=np.int32)\n",
    "            else:\n",
    "                raise Exception(f\"unknown output type: {output}\")\n",
    "            input[k] = value\n",
    "    return input\n",
    "\n",
    "\n",
    "def measure_accuracy(infer, tensor_type: str) -> float:\n",
    "    \"\"\" Function to compute the accuracy from infer_tensorrt output. \"\"\"\n",
    "    \n",
    "    outputs = list()\n",
    "    for start_index in range(0, len(test_tokenized), batch_size):\n",
    "        end_index = start_index + batch_size\n",
    "        data = test_tokenized[start_index:end_index]\n",
    "        inputs: OD[str, np.ndarray] = convert_tensor(data=data, output=tensor_type)\n",
    "        output = infer(inputs)[\"output1\"]\n",
    "        if tensor_type == \"torch\":\n",
    "            output = output.detach().cpu().numpy()\n",
    "        output = np.argmax(output, axis=1).astype(int).tolist()\n",
    "        outputs.extend(output)\n",
    "    return np.mean(np.array(outputs) == np.array(test_tokenized['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4dea34-caa6-4983-b3c8-a1a1f09d08e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T04:00:37.767037Z",
     "iopub.status.busy": "2023-07-24T04:00:37.766870Z",
     "iopub.status.idle": "2023-07-24T04:00:38.095601Z",
     "shell.execute_reply": "2023-07-24T04:00:38.095010Z",
     "shell.execute_reply.started": "2023-07-24T04:00:37.767023Z"
    }
   },
   "source": [
    "Set the parameters for training and evaluation with the Hugging Face Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf87562-210b-4e3f-9e7a-9d92d4fc7b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T04:08:19.181309Z",
     "iopub.status.busy": "2023-07-25T04:08:19.181028Z",
     "iopub.status.idle": "2023-07-25T04:08:19.513608Z",
     "shell.execute_reply": "2023-07-25T04:08:19.513051Z",
     "shell.execute_reply.started": "2023-07-25T04:08:19.181289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89/879412723.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bcb4bf4328403faa7d0bba977e3183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the accuracy metric from the Hugging Face `datasets` library\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "# training arguments for Hugging Face Trainer\n",
    "nb_step = 1000\n",
    "strategy = IntervalStrategy.STEPS\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=model_quantized_dir,\n",
    "    evaluation_strategy=strategy,\n",
    "    eval_steps=nb_step,\n",
    "    logging_steps=nb_step,\n",
    "    save_steps=nb_step,\n",
    "    save_strategy=strategy,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size * 2,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=[],    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f802d-27bd-453a-a70f-e8bc871dbe7a",
   "metadata": {},
   "source": [
    "### STEP 3: Add Quantization Support to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5fef8-993c-41de-ad18-d6d4414bf309",
   "metadata": {},
   "source": [
    "The main idea is to automate the addition of QDQ nodes into the source code of the model. QDQ nodes, which store information required to map between high and low precision numbers, will be positioned both before and after the operations set for quantization.\n",
    "\n",
    "More information here: https://els-rd.github.io/transformer-deploy/quantization/quantization_ast/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bc299-da98-4043-a92f-0a4e18bf9690",
   "metadata": {},
   "source": [
    "________________________________________________________________________________\n",
    "Loop through different percentiles, which are used in the precision mapping, to find the one that results in the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61db43f2-47ed-48a7-a979-3ecd06664b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T21:42:52.748822Z",
     "iopub.status.busy": "2023-07-12T21:42:52.748213Z",
     "iopub.status.idle": "2023-07-12T22:35:30.758022Z",
     "shell.execute_reply": "2023-07-12T22:35:30.757058Z",
     "shell.execute_reply.started": "2023-07-12T21:42:52.748798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile 1 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [10:48<00:00, 162.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile: 99.9\n",
      "{'eval_loss': 0.5294165015220642, 'eval_accuracy': 0.7392358140861135, 'eval_runtime': 142.6743, 'eval_samples_per_second': 98.322, 'eval_steps_per_second': 1.542}\n",
      "{'eval_loss': 0.5294165015220642, 'eval_accuracy': 0.7392358140861135, 'eval_runtime': 142.6743, 'eval_samples_per_second': 98.322, 'eval_steps_per_second': 1.542}\n",
      "percentile 2 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [10:46<00:00, 161.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile: 99.99\n",
      "{'eval_loss': 0.5322121977806091, 'eval_accuracy': 0.7344596521243227, 'eval_runtime': 142.9213, 'eval_samples_per_second': 98.152, 'eval_steps_per_second': 1.539}\n",
      "{'eval_loss': 0.5322121977806091, 'eval_accuracy': 0.7344596521243227, 'eval_runtime': 142.9213, 'eval_samples_per_second': 98.152, 'eval_steps_per_second': 1.539}\n",
      "percentile 3 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [10:43<00:00, 160.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile: 99.999\n",
      "{'eval_loss': 0.5312505960464478, 'eval_accuracy': 0.7581978899344168, 'eval_runtime': 143.0553, 'eval_samples_per_second': 98.06, 'eval_steps_per_second': 1.538}\n",
      "{'eval_loss': 0.5312505960464478, 'eval_accuracy': 0.7581978899344168, 'eval_runtime': 143.0553, 'eval_samples_per_second': 98.06, 'eval_steps_per_second': 1.538}\n",
      "percentile 4 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [10:37<00:00, 159.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile: 99.9999\n",
      "{'eval_loss': 0.537022590637207, 'eval_accuracy': 0.763116623895067, 'eval_runtime': 142.6047, 'eval_samples_per_second': 98.37, 'eval_steps_per_second': 1.543}\n",
      "{'eval_loss': 0.537022590637207, 'eval_accuracy': 0.763116623895067, 'eval_runtime': 142.6047, 'eval_samples_per_second': 98.37, 'eval_steps_per_second': 1.543}\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_dir)\n",
    "for idx, percentile in enumerate([99.9, 99.99, 99.999, 99.9999]):\n",
    "    print(f\"percentile {idx+1} of 4\")\n",
    "    with QATCalibrate(method=\"histogram\", percentile=percentile) as qat:\n",
    "        model_q: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_dir, config=config\n",
    "        )\n",
    "        model_q = model_q.cuda()\n",
    "        qat.setup_model_qat(model_q)  # prepare quantizer to any model\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for start_index in tqdm.tqdm(range(0, 128, batch_size)):\n",
    "                end_index = start_index + batch_size\n",
    "                data = train_tokenized[start_index:end_index]\n",
    "                input_torch = {\n",
    "                    k: torch.tensor(v, dtype=torch.long, device=\"cuda\")\n",
    "                    for k, v in data.items()\n",
    "                    if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]\n",
    "                }\n",
    "                model_q(**input_torch)\n",
    "    trainer = get_trainer(model_q)\n",
    "    print(f\"percentile: {percentile}\")\n",
    "    print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ca544-1855-4b6b-a53f-03ca75b03d12",
   "metadata": {},
   "source": [
    "Add quantization support using the percentile that resulted in the best results from above.\n",
    "\n",
    "That would be `99.9999` for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d812e4-5b77-41ae-907d-78c311d6753e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T04:08:28.654016Z",
     "iopub.status.busy": "2023-07-25T04:08:28.653308Z",
     "iopub.status.idle": "2023-07-25T04:21:56.083520Z",
     "shell.execute_reply": "2023-07-25T04:21:56.082923Z",
     "shell.execute_reply.started": "2023-07-25T04:08:28.654003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [11:10<00:00, 167.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5371240377426147, 'eval_accuracy': 0.7628314798973481, 'eval_runtime': 143.0255, 'eval_samples_per_second': 98.08, 'eval_steps_per_second': 1.538}\n",
      "{'eval_loss': 0.5371240377426147, 'eval_accuracy': 0.7628314798973481, 'eval_runtime': 143.0255, 'eval_samples_per_second': 98.08, 'eval_steps_per_second': 1.538}\n"
     ]
    }
   ],
   "source": [
    "best_percentile = 99.9999  # choose the percentile that had the best evaluation accuracy from the grid search in the cell above\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_dir)\n",
    "with QATCalibrate(method=\"histogram\", percentile=best_percentile) as qat:\n",
    "    model_q: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_dir, config=config, ignore_mismatched_sizes=True\n",
    "    )\n",
    "    \n",
    "    model_q = model_q.cuda()\n",
    "    qat.setup_model_qat(model_q)  # prepare quantizer to any model\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_index in tqdm.tqdm(range(0, 128, batch_size)):\n",
    "            end_index = start_index + batch_size\n",
    "            data = train_tokenized[start_index:end_index]\n",
    "            input_torch = {\n",
    "                k: torch.tensor(v, dtype=torch.long, device=\"cuda\")\n",
    "                for k, v in data.items()\n",
    "                if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]\n",
    "            }\n",
    "            model_q(**input_torch)\n",
    "trainer = get_trainer(model_q)\n",
    "print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e88cb43-406d-429e-8da4-e04022f0453f",
   "metadata": {},
   "source": [
    "### STEP 4: Quantization Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6fb0fd-0242-4cf3-b386-03f1d959c349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T04:26:43.994755Z",
     "iopub.status.busy": "2023-03-30T04:26:43.994452Z",
     "iopub.status.idle": "2023-03-30T04:26:43.999751Z",
     "shell.execute_reply": "2023-03-30T04:26:43.998691Z",
     "shell.execute_reply.started": "2023-03-30T04:26:43.994733Z"
    }
   },
   "source": [
    "\n",
    "**Per layer quantization analysis.**\n",
    "\n",
    "Enable quantization of one layer at a time to detect if the quantization of a specific layer has a larger cost on accuracy than other layers.\n",
    "\n",
    "Layer 1 and 10 seem to be the most sensitive in the example below making them possible candidates to disable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e5f85a-a3fa-44c7-9c08-e66a539ee9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T04:26:30.936639Z",
     "iopub.status.busy": "2023-07-25T04:26:30.935921Z",
     "iopub.status.idle": "2023-07-25T04:38:49.961936Z",
     "shell.execute_reply": "2023-07-25T04:38:49.961348Z",
     "shell.execute_reply.started": "2023-07-25T04:26:30.936599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.0\n",
      "{'eval_loss': 0.4587136507034302, 'eval_accuracy': 0.7879241516966068, 'eval_runtime': 60.0344, 'eval_samples_per_second': 233.666, 'eval_steps_per_second': 3.665}\n",
      "{'eval_loss': 0.4587136507034302, 'eval_accuracy': 0.7879241516966068, 'eval_runtime': 60.0344, 'eval_samples_per_second': 233.666, 'eval_steps_per_second': 3.665}\n",
      "----\n",
      "layer.1\n",
      "{'eval_loss': 0.45947614312171936, 'eval_accuracy': 0.7845024237239806, 'eval_runtime': 75.2785, 'eval_samples_per_second': 186.348, 'eval_steps_per_second': 2.922}\n",
      "{'eval_loss': 0.45947614312171936, 'eval_accuracy': 0.7845024237239806, 'eval_runtime': 75.2785, 'eval_samples_per_second': 186.348, 'eval_steps_per_second': 2.922}\n",
      "----\n",
      "layer.2\n",
      "{'eval_loss': 0.4602658152580261, 'eval_accuracy': 0.785642999714856, 'eval_runtime': 60.3391, 'eval_samples_per_second': 232.486, 'eval_steps_per_second': 3.646}\n",
      "{'eval_loss': 0.4602658152580261, 'eval_accuracy': 0.785642999714856, 'eval_runtime': 60.3391, 'eval_samples_per_second': 232.486, 'eval_steps_per_second': 3.646}\n",
      "----\n",
      "layer.3\n",
      "{'eval_loss': 0.4585624933242798, 'eval_accuracy': 0.7877102936983177, 'eval_runtime': 60.2543, 'eval_samples_per_second': 232.813, 'eval_steps_per_second': 3.651}\n",
      "{'eval_loss': 0.4585624933242798, 'eval_accuracy': 0.7877102936983177, 'eval_runtime': 60.2543, 'eval_samples_per_second': 232.813, 'eval_steps_per_second': 3.651}\n",
      "----\n",
      "layer.4\n",
      "{'eval_loss': 0.4631531834602356, 'eval_accuracy': 0.7855004277159966, 'eval_runtime': 60.4341, 'eval_samples_per_second': 232.121, 'eval_steps_per_second': 3.64}\n",
      "{'eval_loss': 0.4631531834602356, 'eval_accuracy': 0.7855004277159966, 'eval_runtime': 60.4341, 'eval_samples_per_second': 232.121, 'eval_steps_per_second': 3.64}\n",
      "----\n",
      "layer.5\n",
      "{'eval_loss': 0.4608939588069916, 'eval_accuracy': 0.7857142857142857, 'eval_runtime': 60.4346, 'eval_samples_per_second': 232.119, 'eval_steps_per_second': 3.64}\n",
      "{'eval_loss': 0.4608939588069916, 'eval_accuracy': 0.7857142857142857, 'eval_runtime': 60.4346, 'eval_samples_per_second': 232.119, 'eval_steps_per_second': 3.64}\n",
      "----\n",
      "layer.6\n",
      "{'eval_loss': 0.45942410826683044, 'eval_accuracy': 0.7867835757057314, 'eval_runtime': 60.4055, 'eval_samples_per_second': 232.231, 'eval_steps_per_second': 3.642}\n",
      "{'eval_loss': 0.45942410826683044, 'eval_accuracy': 0.7867835757057314, 'eval_runtime': 60.4055, 'eval_samples_per_second': 232.231, 'eval_steps_per_second': 3.642}\n",
      "----\n",
      "layer.7\n",
      "{'eval_loss': 0.45798709988594055, 'eval_accuracy': 0.787639007698888, 'eval_runtime': 60.3953, 'eval_samples_per_second': 232.27, 'eval_steps_per_second': 3.643}\n",
      "{'eval_loss': 0.45798709988594055, 'eval_accuracy': 0.787639007698888, 'eval_runtime': 60.3953, 'eval_samples_per_second': 232.27, 'eval_steps_per_second': 3.643}\n",
      "----\n",
      "layer.8\n",
      "{'eval_loss': 0.4583553969860077, 'eval_accuracy': 0.7868548617051611, 'eval_runtime': 60.2015, 'eval_samples_per_second': 233.018, 'eval_steps_per_second': 3.654}\n",
      "{'eval_loss': 0.4583553969860077, 'eval_accuracy': 0.7868548617051611, 'eval_runtime': 60.2015, 'eval_samples_per_second': 233.018, 'eval_steps_per_second': 3.654}\n",
      "----\n",
      "layer.9\n",
      "{'eval_loss': 0.4606463611125946, 'eval_accuracy': 0.7864984317080126, 'eval_runtime': 60.2565, 'eval_samples_per_second': 232.805, 'eval_steps_per_second': 3.651}\n",
      "{'eval_loss': 0.4606463611125946, 'eval_accuracy': 0.7864984317080126, 'eval_runtime': 60.2565, 'eval_samples_per_second': 232.805, 'eval_steps_per_second': 3.651}\n",
      "----\n",
      "layer.10\n",
      "{'eval_loss': 0.4589366912841797, 'eval_accuracy': 0.784145993726832, 'eval_runtime': 60.4497, 'eval_samples_per_second': 232.061, 'eval_steps_per_second': 3.639}\n",
      "{'eval_loss': 0.4589366912841797, 'eval_accuracy': 0.784145993726832, 'eval_runtime': 60.4497, 'eval_samples_per_second': 232.061, 'eval_steps_per_second': 3.639}\n",
      "----\n",
      "layer.11\n",
      "{'eval_loss': 0.459603875875473, 'eval_accuracy': 0.7864271457085829, 'eval_runtime': 60.4976, 'eval_samples_per_second': 231.877, 'eval_steps_per_second': 3.637}\n",
      "{'eval_loss': 0.459603875875473, 'eval_accuracy': 0.7864271457085829, 'eval_runtime': 60.4976, 'eval_samples_per_second': 231.877, 'eval_steps_per_second': 3.637}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    layer_name = f\"layer.{i}\"\n",
    "    print(layer_name)\n",
    "    for name, module in model_q.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if layer_name in name:\n",
    "                module.enable_quant()\n",
    "            else:\n",
    "                module.disable_quant()\n",
    "    print(trainer.evaluate())\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96adecf8-ee8a-4ed3-9f75-a48a7d83c54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T04:27:58.989532Z",
     "iopub.status.busy": "2023-03-30T04:27:58.989261Z",
     "iopub.status.idle": "2023-03-30T04:27:58.993678Z",
     "shell.execute_reply": "2023-03-30T04:27:58.992809Z",
     "shell.execute_reply.started": "2023-03-30T04:27:58.989512Z"
    }
   },
   "source": [
    "**Operator quantization analysis**\n",
    "\n",
    "Enable quantization of one operator type at a time to detect if a specific operator has a larger cost on accuracy.\n",
    "\n",
    "The LayerNorm operation seems to be one of the most sensitive in the example below making it apossible candidate to disable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a3adbda-61db-4e3a-8173-47d9a5537875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T04:38:49.963384Z",
     "iopub.status.busy": "2023-07-25T04:38:49.963092Z",
     "iopub.status.idle": "2023-07-25T04:52:53.359553Z",
     "shell.execute_reply": "2023-07-25T04:52:53.358816Z",
     "shell.execute_reply.started": "2023-07-25T04:38:49.963366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n",
      "{'eval_loss': 0.4594363272190094, 'eval_accuracy': 0.7865697177074422, 'eval_runtime': 56.8388, 'eval_samples_per_second': 246.803, 'eval_steps_per_second': 3.871}\n",
      "{'eval_loss': 0.4594363272190094, 'eval_accuracy': 0.7865697177074422, 'eval_runtime': 56.8388, 'eval_samples_per_second': 246.803, 'eval_steps_per_second': 3.871}\n",
      "----\n",
      "key\n",
      "{'eval_loss': 0.4590598940849304, 'eval_accuracy': 0.7869261477045908, 'eval_runtime': 56.6929, 'eval_samples_per_second': 247.438, 'eval_steps_per_second': 3.881}\n",
      "{'eval_loss': 0.4590598940849304, 'eval_accuracy': 0.7869261477045908, 'eval_runtime': 56.6929, 'eval_samples_per_second': 247.438, 'eval_steps_per_second': 3.881}\n",
      "----\n",
      "value\n",
      "{'eval_loss': 0.45914191007614136, 'eval_accuracy': 0.7858568577131452, 'eval_runtime': 56.8126, 'eval_samples_per_second': 246.917, 'eval_steps_per_second': 3.872}\n",
      "{'eval_loss': 0.45914191007614136, 'eval_accuracy': 0.7858568577131452, 'eval_runtime': 56.8126, 'eval_samples_per_second': 246.917, 'eval_steps_per_second': 3.872}\n",
      "----\n",
      "matmul\n",
      "{'eval_loss': 0.4663393497467041, 'eval_accuracy': 0.7845024237239806, 'eval_runtime': 90.7365, 'eval_samples_per_second': 154.602, 'eval_steps_per_second': 2.425}\n",
      "{'eval_loss': 0.4663393497467041, 'eval_accuracy': 0.7845024237239806, 'eval_runtime': 90.7365, 'eval_samples_per_second': 154.602, 'eval_steps_per_second': 2.425}\n",
      "----\n",
      "matmul_quantizer_0\n",
      "{'eval_loss': 0.4592844247817993, 'eval_accuracy': 0.7859994297120045, 'eval_runtime': 57.4484, 'eval_samples_per_second': 244.184, 'eval_steps_per_second': 3.83}\n",
      "{'eval_loss': 0.4592844247817993, 'eval_accuracy': 0.7859994297120045, 'eval_runtime': 57.4484, 'eval_samples_per_second': 244.184, 'eval_steps_per_second': 3.83}\n",
      "----\n",
      "matmul_quantizer_1\n",
      "{'eval_loss': 0.45941871404647827, 'eval_accuracy': 0.7854291417165669, 'eval_runtime': 57.4447, 'eval_samples_per_second': 244.2, 'eval_steps_per_second': 3.83}\n",
      "{'eval_loss': 0.45941871404647827, 'eval_accuracy': 0.7854291417165669, 'eval_runtime': 57.4447, 'eval_samples_per_second': 244.2, 'eval_steps_per_second': 3.83}\n",
      "----\n",
      "matmul_quantizer_2\n",
      "{'eval_loss': 0.46635866165161133, 'eval_accuracy': 0.7848588537211292, 'eval_runtime': 77.8526, 'eval_samples_per_second': 180.187, 'eval_steps_per_second': 2.826}\n",
      "{'eval_loss': 0.46635866165161133, 'eval_accuracy': 0.7848588537211292, 'eval_runtime': 77.8526, 'eval_samples_per_second': 180.187, 'eval_steps_per_second': 2.826}\n",
      "----\n",
      "matmul_quantizer_3\n",
      "{'eval_loss': 0.45932674407958984, 'eval_accuracy': 0.7862845737097234, 'eval_runtime': 57.2232, 'eval_samples_per_second': 245.145, 'eval_steps_per_second': 3.845}\n",
      "{'eval_loss': 0.45932674407958984, 'eval_accuracy': 0.7862845737097234, 'eval_runtime': 57.2232, 'eval_samples_per_second': 245.145, 'eval_steps_per_second': 3.845}\n",
      "----\n",
      "dense\n",
      "{'eval_loss': 0.5009364485740662, 'eval_accuracy': 0.7835757057313943, 'eval_runtime': 78.6039, 'eval_samples_per_second': 178.464, 'eval_steps_per_second': 2.799}\n",
      "{'eval_loss': 0.5009364485740662, 'eval_accuracy': 0.7835757057313943, 'eval_runtime': 78.6039, 'eval_samples_per_second': 178.464, 'eval_steps_per_second': 2.799}\n",
      "----\n",
      "dense._input\n",
      "{'eval_loss': 0.5021378993988037, 'eval_accuracy': 0.7811519817507842, 'eval_runtime': 76.8343, 'eval_samples_per_second': 182.575, 'eval_steps_per_second': 2.863}\n",
      "{'eval_loss': 0.5021378993988037, 'eval_accuracy': 0.7811519817507842, 'eval_runtime': 76.8343, 'eval_samples_per_second': 182.575, 'eval_steps_per_second': 2.863}\n",
      "----\n",
      "dense._weight\n",
      "{'eval_loss': 0.45979538559913635, 'eval_accuracy': 0.786142001710864, 'eval_runtime': 55.1627, 'eval_samples_per_second': 254.302, 'eval_steps_per_second': 3.988}\n",
      "{'eval_loss': 0.45979538559913635, 'eval_accuracy': 0.786142001710864, 'eval_runtime': 55.1627, 'eval_samples_per_second': 254.302, 'eval_steps_per_second': 3.988}\n",
      "----\n",
      "layernorm\n",
      "{'eval_loss': 0.5061509013175964, 'eval_accuracy': 0.7706729398346165, 'eval_runtime': 68.3974, 'eval_samples_per_second': 205.095, 'eval_steps_per_second': 3.216}\n",
      "{'eval_loss': 0.5061509013175964, 'eval_accuracy': 0.7706729398346165, 'eval_runtime': 68.3974, 'eval_samples_per_second': 205.095, 'eval_steps_per_second': 3.216}\n",
      "----\n",
      "pooler\n",
      "{'eval_loss': 0.45937857031822205, 'eval_accuracy': 0.7859281437125748, 'eval_runtime': 53.3003, 'eval_samples_per_second': 263.188, 'eval_steps_per_second': 4.128}\n",
      "{'eval_loss': 0.45937857031822205, 'eval_accuracy': 0.7859281437125748, 'eval_runtime': 53.3003, 'eval_samples_per_second': 263.188, 'eval_steps_per_second': 4.128}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for op in [\"query\", \"key\", \"value\",\n",
    "           \"matmul\", \"matmul_quantizer_0\", \"matmul_quantizer_1\", \"matmul_quantizer_2\", \"matmul_quantizer_3\", \n",
    "           \"dense\", \"dense._input\", \"dense._weight\", \n",
    "           \"layernorm\", \"pooler\"]:\n",
    "    \n",
    "    for name, module in model_q.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if op in name:\n",
    "                module.enable_quant()\n",
    "            else:\n",
    "                module.disable_quant()\n",
    "    print(op)\n",
    "    print(trainer.evaluate())\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f2f61-0968-4b03-a3cd-1a8e252fcc8f",
   "metadata": {},
   "source": [
    "The goal is to disable quantization for as few operations as possible while preserving accuracy as much as possible. \n",
    "\n",
    "Through some trial and error of different combinations of layers I have settled on disabling LayerNorm on Layer 2 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d026a3e-5f59-4ee8-8f09-6a8629d04aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T15:15:48.920068Z",
     "iopub.status.busy": "2023-07-25T15:15:48.918904Z",
     "iopub.status.idle": "2023-07-25T15:18:11.257083Z",
     "shell.execute_reply": "2023-07-25T15:18:11.256406Z",
     "shell.execute_reply.started": "2023-07-25T15:15:48.920031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disable bert.encoder.layer.2.output.layernorm_quantizer_0\n",
      "disable bert.encoder.layer.2.output.layernorm_quantizer_1\n",
      "disable bert.encoder.layer.10.output.layernorm_quantizer_0\n",
      "disable bert.encoder.layer.10.output.layernorm_quantizer_1\n",
      "{'eval_loss': 0.534470796585083, 'eval_accuracy': 0.7723838038209295, 'eval_runtime': 142.3247, 'eval_samples_per_second': 98.563, 'eval_steps_per_second': 1.546}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.534470796585083,\n",
       " 'eval_accuracy': 0.7723838038209295,\n",
       " 'eval_runtime': 142.3247,\n",
       " 'eval_samples_per_second': 98.563,\n",
       " 'eval_steps_per_second': 1.546}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, module in model_q.named_modules():\n",
    "    if isinstance(module, quant_nn.TensorQuantizer): \n",
    "        if any([l in name for l in [\"layer.2\", \"layer.10\"]]) and \"layernorm\" in name and \"attention\" not in name: \n",
    "            print(f\"disable {name}\")\n",
    "            module.disable_quant() \n",
    "        \n",
    "        else:\n",
    "            module.enable_quant()\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48fb92-40a4-4877-b09b-706f3b58a6dd",
   "metadata": {},
   "source": [
    "### STEP 5: Quantization aware training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053fc48-e606-4f0a-9c62-80f50c2666a9",
   "metadata": {},
   "source": [
    "After having quantized the model, fine-tune again with a lower learning rate to recover some of the lost accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ecea50b-a2fd-48e5-81ce-d1a2ba381f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T15:23:37.612544Z",
     "iopub.status.busy": "2023-07-25T15:23:37.611973Z",
     "iopub.status.idle": "2023-07-25T16:14:15.696440Z",
     "shell.execute_reply": "2023-07-25T16:14:15.695897Z",
     "shell.execute_reply.started": "2023-07-25T15:23:37.612522Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4811, 'learning_rate': 7.14856002281152e-08, 'epoch': 0.29}\n",
      "{'eval_loss': 0.4795648753643036, 'eval_accuracy': 0.7801383046980823, 'eval_runtime': 141.8049, 'eval_samples_per_second': 98.918, 'eval_steps_per_second': 1.551, 'epoch': 0.29}\n",
      "{'loss': 0.4497, 'learning_rate': 4.2971200456230394e-08, 'epoch': 0.57}\n",
      "{'eval_loss': 0.47320234775543213, 'eval_accuracy': 0.7775718257645968, 'eval_runtime': 142.2774, 'eval_samples_per_second': 98.589, 'eval_steps_per_second': 1.546, 'epoch': 0.57}\n",
      "{'loss': 0.4397, 'learning_rate': 1.4513829483889364e-08, 'epoch': 0.86}\n",
      "{'eval_loss': 0.4719729423522949, 'eval_accuracy': 0.7802095957795679, 'eval_runtime': 141.266, 'eval_samples_per_second': 99.295, 'eval_steps_per_second': 1.557, 'epoch': 0.86}\n",
      "{'train_runtime': 2844.0087, 'train_samples_per_second': 39.457, 'train_steps_per_second': 1.233, 'train_loss': 0.45373689179954824, 'epoch': 1.0}\n",
      "evaluation with test dataset\n",
      "{'eval_loss': 0.4707139730453491, 'eval_accuracy': 0.7808668377530653, 'eval_runtime': 141.2804, 'eval_samples_per_second': 99.292, 'eval_steps_per_second': 1.557, 'epoch': 1.0}\n",
      "{'eval_loss': 0.4707139730453491, 'eval_accuracy': 0.7808668377530653, 'eval_runtime': 141.2804, 'eval_samples_per_second': 99.292, 'eval_steps_per_second': 1.557, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "args.learning_rate = 1e-7\n",
    "args.num_train_epochs = 1\n",
    "trainer = get_trainer(model_q)\n",
    "trainer.eval_dataset=val_tokenized\n",
    "trainer.train()\n",
    "\n",
    "print(\"evaluation with test dataset\")\n",
    "trainer.eval_dataset = test_tokenized\n",
    "print(trainer.evaluate())\n",
    "\n",
    "model_q.save_pretrained(\"../models/model-qat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c939f-a94d-472d-917d-a6ed2ac00dd8",
   "metadata": {},
   "source": [
    "### STEP 6: Export the QDQ Pytorch model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b85bb88-7e3d-4128-b193-abac897db6f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:16:50.675807Z",
     "iopub.status.busy": "2023-07-25T16:16:50.675141Z",
     "iopub.status.idle": "2023-07-25T16:17:03.605341Z",
     "shell.execute_reply": "2023-07-25T16:17:03.604794Z",
     "shell.execute_reply.started": "2023-07-25T16:16:50.675785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:283: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:291: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = train_tokenized[1:3]\n",
    "input_torch = convert_tensor(data, output=\"torch\")\n",
    "convert_to_onnx(\n",
    "    model_pytorch=model_q,\n",
    "    output_path=\"../models/model_qat.onnx\",\n",
    "    inputs_pytorch=input_torch,\n",
    "    quantization=True,\n",
    "    var_output_seq=False,\n",
    "    output_names = [\"output1\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "399977f2-b4ea-46bd-ada1-367fd38069f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:19:55.424925Z",
     "iopub.status.busy": "2023-07-25T16:19:55.424153Z",
     "iopub.status.idle": "2023-07-25T16:19:55.448190Z",
     "shell.execute_reply": "2023-07-25T16:19:55.447491Z",
     "shell.execute_reply.started": "2023-07-25T16:19:55.424901Z"
    }
   },
   "outputs": [],
   "source": [
    "del model_q\n",
    "QATCalibrate.restore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7289f-6509-4a10-8938-d7eac719c022",
   "metadata": {},
   "source": [
    "### STEP 7: TensorRT INT8 Quantization Benchmark\n",
    "\n",
    "Convert ONNX graph to TensorRT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eb04cd4-5065-4f98-bb72-162610575c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:20:00.241492Z",
     "iopub.status.busy": "2023-07-25T16:20:00.240845Z",
     "iopub.status.idle": "2023-07-25T16:23:25.932734Z",
     "shell.execute_reply": "2023-07-25T16:23:25.932013Z",
     "shell.execute_reply.started": "2023-07-25T16:20:00.241467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/25/2023-16:20:01] [TRT] [E] 3: [builderConfig.cpp::validatePool::313] Error Code 3: API Usage Error (Parameter check failed at: optimizer/api/builderConfig.cpp::validatePool::313, condition: false. Setting DLA memory pool size on TensorRT build with DLA disabled.\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "engine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"../models/model_qat.onnx\",\n",
    "    logger=trt_logger,\n",
    "    min_shape=(1, max_seq_len),\n",
    "    optimal_shape=(batch_size, max_seq_len),\n",
    "    max_shape=(batch_size, max_seq_len),\n",
    "    workspace_size=10000 * 1024 * 1024,\n",
    "    fp16=True,\n",
    "    int8=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7d7ff-14a5-41fa-a82f-e89486d05396",
   "metadata": {},
   "source": [
    "Prepare input and output buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb204012-9b88-452f-a477-0197ea29f9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:25:34.162730Z",
     "iopub.status.busy": "2023-07-25T16:25:34.162275Z",
     "iopub.status.idle": "2023-07-25T16:25:34.873896Z",
     "shell.execute_reply": "2023-07-25T16:25:34.873238Z",
     "shell.execute_reply.started": "2023-07-25T16:25:34.162687Z"
    }
   },
   "outputs": [],
   "source": [
    "context: IExecutionContext = engine.create_execution_context()\n",
    "context.set_optimization_profile_async(\n",
    "    profile_index=profile_index, stream_handle=torch.cuda.current_stream().cuda_stream\n",
    ")\n",
    "input_binding_idxs, output_binding_idxs = get_binding_idxs(engine, profile_index)  # type: List[int], List[int]\n",
    "\n",
    "\n",
    "data = train_tokenized[0:batch_size]\n",
    "input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "input_np: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b334205-be22-4587-ad4a-9cad6bf907a0",
   "metadata": {},
   "source": [
    "Check that inference is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e0f4939-5032-4d8f-99bd-988df6e7b557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:25:37.900810Z",
     "iopub.status.busy": "2023-07-25T16:25:37.900275Z",
     "iopub.status.idle": "2023-07-25T16:25:37.950534Z",
     "shell.execute_reply": "2023-07-25T16:25:37.949817Z",
     "shell.execute_reply.started": "2023-07-25T16:25:37.900789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output1': tensor([[ 8.8974e-01, -3.6593e-01],\n",
      "        [-1.5406e+00,  1.1372e+00],\n",
      "        [ 7.6251e-01, -1.3573e-01],\n",
      "        [-1.0282e+00,  9.7014e-01],\n",
      "        [ 4.2417e-01, -1.8649e-03],\n",
      "        [-2.6301e-01,  3.6717e-01],\n",
      "        [ 2.8515e-01,  1.1626e-01],\n",
      "        [ 7.6680e-01, -1.8062e-01],\n",
      "        [-8.3431e-01,  7.3697e-01],\n",
      "        [-1.3840e+00,  8.7692e-01],\n",
      "        [ 1.8685e+00, -9.7738e-01],\n",
      "        [ 5.9061e-01, -3.5877e-02],\n",
      "        [ 1.6593e+00, -7.9597e-01],\n",
      "        [ 1.7117e+00, -8.3231e-01],\n",
      "        [-1.3771e-01,  3.2420e-01],\n",
      "        [-8.6504e-01,  7.9855e-01],\n",
      "        [ 1.4455e+00, -5.3692e-01],\n",
      "        [-9.1140e-01,  8.2719e-01],\n",
      "        [-1.3829e+00,  7.9771e-01],\n",
      "        [ 1.7107e+00, -7.6251e-01],\n",
      "        [ 9.0488e-01, -1.5545e-01],\n",
      "        [ 1.5613e+00, -7.3928e-01],\n",
      "        [ 8.3291e-01, -2.2420e-01],\n",
      "        [-3.3598e-01,  5.0985e-01],\n",
      "        [ 5.8289e-01,  4.4166e-03],\n",
      "        [-1.1288e+00,  9.4518e-01],\n",
      "        [ 9.4472e-01, -4.0603e-01],\n",
      "        [-1.3020e+00,  9.9439e-01],\n",
      "        [ 9.6428e-01, -2.5903e-01],\n",
      "        [ 1.0644e+00, -3.8545e-01],\n",
      "        [ 2.0406e+00, -1.0997e+00],\n",
      "        [-1.8886e+00,  1.1494e+00]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "tensorrt_output = infer_tensorrt(\n",
    "    context=context,\n",
    "    inputs=input_torch,\n",
    "    input_binding_idxs=input_binding_idxs,\n",
    "    output_binding_idxs=output_binding_idxs,\n",
    ")\n",
    "\n",
    "print(tensorrt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56e7f6-f02c-4d44-ba36-63bebadd610a",
   "metadata": {},
   "source": [
    "Measure accuracy on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d053ab1-328c-42c5-bd89-73c5d3ebbb62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:25:44.568515Z",
     "iopub.status.busy": "2023-07-25T16:25:44.567847Z",
     "iopub.status.idle": "2023-07-25T16:26:10.399072Z",
     "shell.execute_reply": "2023-07-25T16:26:10.398435Z",
     "shell.execute_reply.started": "2023-07-25T16:25:44.568490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7811519817507842"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_trt = lambda inputs: infer_tensorrt(\n",
    "    context=context,\n",
    "    inputs=inputs,\n",
    "    input_binding_idxs=input_binding_idxs,\n",
    "    output_binding_idxs=output_binding_idxs,\n",
    ")\n",
    "\n",
    "measure_accuracy(infer=infer_trt, tensor_type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb5a17-5715-4f73-8015-eb84d2be92aa",
   "metadata": {},
   "source": [
    "Save the engine and reload it into a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef20f936-7be7-4789-804e-a8381c16c167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:26:28.237670Z",
     "iopub.status.busy": "2023-07-25T16:26:28.237038Z",
     "iopub.status.idle": "2023-07-25T16:26:29.752249Z",
     "shell.execute_reply": "2023-07-25T16:26:29.751624Z",
     "shell.execute_reply.started": "2023-07-25T16:26:28.237648Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the engine\n",
    "save_engine(engine, \"../models/stack_int8_fp16_model.trt\")\n",
    "\n",
    "# del the engine and context from memory\n",
    "del engine, context\n",
    "\n",
    "# load the saved engine - this includes the function for inference that handles the context and binding indices\n",
    "trt_engine_int8_fp16 = load_engine(runtime=runtime, engine_file_path=\"../models/stack_int8_fp16_model.trt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aeccbe-b207-49c8-80b5-5d8b7204294d",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "620225e4-6bfe-4805-9ffa-255c5dcd933a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:26:36.661106Z",
     "iopub.status.busy": "2023-07-25T16:26:36.660570Z",
     "iopub.status.idle": "2023-07-25T16:27:02.467331Z",
     "shell.execute_reply": "2023-07-25T16:27:02.466467Z",
     "shell.execute_reply.started": "2023-07-25T16:26:36.661084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7816067351598174\n",
      "Execution time: 25.8\n",
      "Samples per second: 543\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 32\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "    tensorrt_output = trt_engine_int8_fp16(\n",
    "        inputs=input_torch,\n",
    "    )\n",
    "    \n",
    "    preds=tensorrt_output['output1'].argmax(-1)\n",
    "    labels = torch.tensor(data['label']).cuda()\n",
    "    correct+=torch.sum(preds==labels).item()\n",
    "    total+=labels.shape[0]\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aed9fc-5ad2-42fa-b924-d0b68e4688f1",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e352f40-f07f-46f7-8530-c57e0f64553d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T16:28:03.676637Z",
     "iopub.status.busy": "2023-07-25T16:28:03.675956Z",
     "iopub.status.idle": "2023-07-25T16:28:42.684614Z",
     "shell.execute_reply": "2023-07-25T16:28:42.683920Z",
     "shell.execute_reply.started": "2023-07-25T16:28:03.676615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7813658397490733\n",
      "Execution time: 39.0\n",
      "Samples per second: 359\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "    tensorrt_output = trt_engine_int8_fp16(\n",
    "        inputs=input_torch,\n",
    "    )\n",
    "    \n",
    "    preds=tensorrt_output['output1'].argmax(-1)\n",
    "    labels = torch.tensor(data['label']).cuda()\n",
    "    correct+=torch.sum(preds==labels).item()\n",
    "    total+=labels.shape[0]\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ec336-a28f-42bf-9973-9c4e5391a718",
   "metadata": {},
   "source": [
    "### STEP 8: Pytorch GPU Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381977f9-4b3e-468c-b4b7-8c672d884f7b",
   "metadata": {},
   "source": [
    "#### Floating Point 32\n",
    "Load the pytorch FP32 version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d037db64-6921-428e-92d0-41b1b23f6970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T04:10:22.822777Z",
     "iopub.status.busy": "2023-07-24T04:10:22.822481Z",
     "iopub.status.idle": "2023-07-24T04:10:28.888127Z",
     "shell.execute_reply": "2023-07-24T04:10:28.887279Z",
     "shell.execute_reply.started": "2023-07-24T04:10:22.822757Z"
    }
   },
   "outputs": [],
   "source": [
    "pytorch_model_fp32 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_dir, num_labels=num_labels)\n",
    "pytorch_model_fp32 = pytorch_model_fp32.cuda()\n",
    "pytorch_model_fp32 = pytorch_model_fp32.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfad4e5-7b71-4744-9681-691483b39f18",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7f39440-91e1-4347-aba9-0d0b273b4c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T20:50:26.917008Z",
     "iopub.status.busy": "2023-07-22T20:50:26.916390Z",
     "iopub.status.idle": "2023-07-22T20:52:18.414235Z",
     "shell.execute_reply": "2023-07-22T20:52:18.413453Z",
     "shell.execute_reply.started": "2023-07-22T20:50:26.916982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7857448630136986\n",
      "Execution time: 111.5\n",
      "Samples per second: 125\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 32\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        pytorch_output = pytorch_model_fp32(**input_torch)\n",
    "    \n",
    "        preds=pytorch_output.logits.argmax(-1)\n",
    "        labels = torch.tensor(data['label']).cuda()\n",
    "        correct+=torch.sum(preds==labels).item()\n",
    "        total+=labels.shape[0]\n",
    "        \n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ea5ca-adf2-44d3-a9af-86d56a8c4f19",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80edbcd4-7567-408d-9cd9-1ce9fe7e1d14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T04:10:50.066937Z",
     "iopub.status.busy": "2023-07-24T04:10:50.066406Z",
     "iopub.status.idle": "2023-07-24T04:13:20.304599Z",
     "shell.execute_reply": "2023-07-24T04:13:20.303918Z",
     "shell.execute_reply.started": "2023-07-24T04:10:50.066914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7857142857142857\n",
      "Execution time: 150.2\n",
      "Samples per second: 93\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "    with torch.inference_mode():\n",
    "        pytorch_output = pytorch_model_fp32(**input_torch)\n",
    "    \n",
    "        preds=pytorch_output.logits.argmax(-1)\n",
    "        labels = torch.tensor(data['label']).cuda()\n",
    "        correct+=torch.sum(preds==labels).item()\n",
    "        total+=labels.shape[0]\n",
    "        \n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace5ad5-c632-4d3f-9235-6fa6f0890b4e",
   "metadata": {},
   "source": [
    "#### Floating Point 16\n",
    "Load the pytorch FP16 version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "286701c9-8b2f-46c2-836b-b87075c8283a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T04:14:18.111989Z",
     "iopub.status.busy": "2023-07-24T04:14:18.111422Z",
     "iopub.status.idle": "2023-07-24T04:14:20.035441Z",
     "shell.execute_reply": "2023-07-24T04:14:20.034835Z",
     "shell.execute_reply.started": "2023-07-24T04:14:18.111969Z"
    }
   },
   "outputs": [],
   "source": [
    "pytorch_model_fp16 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_dir, num_labels=num_labels)\n",
    "pytorch_model_fp16 = pytorch_model_fp16.half()\n",
    "pytorch_model_fp16 = pytorch_model_fp16.cuda()\n",
    "pytorch_model_fp16 = pytorch_model_fp16.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa546e4-c818-406e-9a04-054d976805a0",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc22c56d-1e6f-4194-94c5-35e83522f283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T20:52:19.227794Z",
     "iopub.status.busy": "2023-07-22T20:52:19.227346Z",
     "iopub.status.idle": "2023-07-22T20:52:57.045302Z",
     "shell.execute_reply": "2023-07-22T20:52:57.044671Z",
     "shell.execute_reply.started": "2023-07-22T20:52:19.227776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7858162100456622\n",
      "Execution time: 37.8\n",
      "Samples per second: 370\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 32\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        pytorch_output = pytorch_model_fp16(**input_torch)\n",
    "    \n",
    "        preds=pytorch_output.logits.argmax(-1)\n",
    "        labels = torch.tensor(data['label']).cuda()\n",
    "        correct+=torch.sum(preds==labels).item()\n",
    "        total+=labels.shape[0]\n",
    "\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc45d9-fb41-40e1-9ba3-862ae03144a8",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "409b0520-c8b0-4f10-abdb-526a6e4a01fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T04:14:46.493073Z",
     "iopub.status.busy": "2023-07-24T04:14:46.492310Z",
     "iopub.status.idle": "2023-07-24T04:16:12.501526Z",
     "shell.execute_reply": "2023-07-24T04:16:12.500909Z",
     "shell.execute_reply.started": "2023-07-24T04:14:46.493053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7857855717137154\n",
      "Execution time: 86.0\n",
      "Samples per second: 163\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        pytorch_output = pytorch_model_fp16(**input_torch)\n",
    "    \n",
    "        preds=pytorch_output.logits.argmax(-1)\n",
    "        labels = torch.tensor(data['label']).cuda()\n",
    "        correct+=torch.sum(preds==labels).item()\n",
    "        total+=labels.shape[0]\n",
    "\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e4ace-8398-4ab6-bf0b-efc2796f9c24",
   "metadata": {},
   "source": [
    "### STEP 9: TensorRT FP16 Benchmark\n",
    "\n",
    "Check the performance on mixed precision (FP16, no quantization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1212b2c9-34c9-454a-8ce6-1de5f8e7e711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T15:42:28.691914Z",
     "iopub.status.busy": "2023-07-22T15:42:28.691308Z",
     "iopub.status.idle": "2023-07-22T15:42:42.349766Z",
     "shell.execute_reply": "2023-07-22T15:42:42.349004Z",
     "shell.execute_reply.started": "2023-07-22T15:42:28.691893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = train_tokenized[0:batch_size]\n",
    "input_torch = convert_tensor(data, output=\"torch\")\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_dir)\n",
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_dir, config=config\n",
    "    )\n",
    "\n",
    "baseline_model = baseline_model.cuda()\n",
    "\n",
    "convert_to_onnx(\n",
    "    baseline_model, output_path=\"../models/baseline.onnx\", inputs_pytorch=input_torch, quantization=False, var_output_seq=False,\n",
    "    output_names = [\"output1\"]\n",
    ")\n",
    "\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be030bd9-4bde-4e11-b4d6-c66f95041cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T15:42:50.513852Z",
     "iopub.status.busy": "2023-07-22T15:42:50.513584Z",
     "iopub.status.idle": "2023-07-22T15:52:06.017776Z",
     "shell.execute_reply": "2023-07-22T15:52:06.016984Z",
     "shell.execute_reply.started": "2023-07-22T15:42:50.513831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/22/2023-15:42:51] [TRT] [E] 3: [builderConfig.cpp::validatePool::313] Error Code 3: API Usage Error (Parameter check failed at: optimizer/api/builderConfig.cpp::validatePool::313, condition: false. Setting DLA memory pool size on TensorRT build with DLA disabled.\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "max_seq_len=512\n",
    "batch_size=32\n",
    "engine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"../models/baseline.onnx\",\n",
    "    logger=trt_logger,\n",
    "    min_shape=(1, max_seq_len),\n",
    "    optimal_shape=(batch_size, max_seq_len),\n",
    "    max_shape=(batch_size, max_seq_len),\n",
    "    workspace_size=10000 * 1024 * 1024,\n",
    "    fp16=True,\n",
    "    int8=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477ff19-aa63-40c2-8f0f-f18129d9e52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T15:58:57.909276Z",
     "iopub.status.busy": "2023-07-22T15:58:57.908363Z",
     "iopub.status.idle": "2023-07-22T15:58:58.335791Z",
     "shell.execute_reply": "2023-07-22T15:58:58.335213Z",
     "shell.execute_reply.started": "2023-07-22T15:58:57.909243Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the engine\n",
    "save_engine(engine, \"../models/stack_fp16_model.trt\")\n",
    "\n",
    "# del the engine from memory\n",
    "del engine\n",
    "\n",
    "# load the saved engine - this includes the function for inference that handles the context and binding indices\n",
    "trt_engine_fp16 = load_engine(runtime=runtime, engine_file_path=\"../models/stack_fp16_model.trt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a844381-8b9b-42f3-ba01-562161692f58",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dff6be5-31ee-49b5-8a03-19bbc7c71d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T20:47:50.642042Z",
     "iopub.status.busy": "2023-07-22T20:47:50.641280Z",
     "iopub.status.idle": "2023-07-22T20:48:18.073034Z",
     "shell.execute_reply": "2023-07-22T20:48:18.072545Z",
     "shell.execute_reply.started": "2023-07-22T20:47:50.642010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7857448630136986\n",
      "Execution time: 27.4\n",
      "Samples per second: 511\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 32\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "    tensorrt_output = trt_engine_fp16(\n",
    "        inputs=input_torch,\n",
    "    )\n",
    "    \n",
    "    preds=tensorrt_output['output1'].argmax(-1)\n",
    "    labels = torch.tensor(data['label']).cuda()\n",
    "    correct+=torch.sum(preds==labels).item()\n",
    "    total+=labels.shape[0]\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4550d198-5299-4bfc-b716-8347a3b1e8ba",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d14087f-8622-44f2-9ae1-d8ce07489584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T04:17:32.131291Z",
     "iopub.status.busy": "2023-07-24T04:17:32.130700Z",
     "iopub.status.idle": "2023-07-24T04:18:13.314538Z",
     "shell.execute_reply": "2023-07-24T04:18:13.313790Z",
     "shell.execute_reply.started": "2023-07-24T04:17:32.131261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.785642999714856\n",
      "Execution time: 41.2\n",
      "Samples per second: 340\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "    tensorrt_output = trt_engine_fp16(\n",
    "        inputs=input_torch,\n",
    "    )\n",
    "    \n",
    "    preds=tensorrt_output['output1'].argmax(-1)\n",
    "    labels = torch.tensor(data['label']).cuda()\n",
    "    correct+=torch.sum(preds==labels).item()\n",
    "    total+=labels.shape[0]\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ed450-e39d-40dc-b52b-de7899a1e68f",
   "metadata": {},
   "source": [
    "### STEP 10: FP16 ONNX Runtime Benchmark\n",
    "\n",
    "Convert to model to ONNX Runtime using all available cores and enabling any possible optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef1abed6-419d-48f5-b4c5-7f2677315a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T16:40:31.433216Z",
     "iopub.status.busy": "2023-07-22T16:40:31.432617Z",
     "iopub.status.idle": "2023-07-22T16:41:09.821809Z",
     "shell.execute_reply": "2023-07-22T16:41:09.821000Z",
     "shell.execute_reply.started": "2023-07-22T16:40:31.433194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "rm: cannot remove 'baseline-optimized.onnx': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "optimize_onnx(\n",
    "    onnx_path=\"../models/baseline.onnx\",\n",
    "    onnx_optim_model_path=\"../models/baseline-optimized.onnx\",\n",
    "    fp16=True,\n",
    "    use_cuda=True,\n",
    "    num_attention_heads=12,\n",
    "    hidden_size=768,\n",
    "    architecture=\"bert\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f199db92-75cd-4afb-af36-7a425196bad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T04:19:19.365408Z",
     "iopub.status.busy": "2023-07-24T04:19:19.364696Z",
     "iopub.status.idle": "2023-07-24T04:19:21.738344Z",
     "shell.execute_reply": "2023-07-24T04:19:21.737605Z",
     "shell.execute_reply.started": "2023-07-24T04:19:19.365382Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx_model_fp16 = create_model_for_provider(path=\"../models/baseline-optimized.onnx\", provider_to_use=\"CUDAExecutionProvider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5069d5-8677-4490-9081-95948d550b99",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5db5dd9-a2a4-40ff-a227-2006f06766ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T20:48:56.040752Z",
     "iopub.status.busy": "2023-07-22T20:48:56.039936Z",
     "iopub.status.idle": "2023-07-22T20:49:30.414354Z",
     "shell.execute_reply": "2023-07-22T20:49:30.413862Z",
     "shell.execute_reply.started": "2023-07-22T20:48:56.040694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7858162100456622\n",
      "Execution time: 34.4\n",
      "Samples per second: 408\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 32\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_np: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")\n",
    "\n",
    "    onnx_output = onnx_model_fp16.run(\n",
    "        None,\n",
    "        input_np,\n",
    "    )\n",
    "    \n",
    "    preds=onnx_output[0].argmax(-1)\n",
    "    labels = np.array(data['label'])\n",
    "    correct+=np.sum(preds==labels)\n",
    "    total+=labels.shape[0]\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bea719-24e4-4616-862f-4eaae5834649",
   "metadata": {},
   "source": [
    "Measure accuracy and speed with a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d19a5025-6cc6-4a6c-bca3-afe19a62cc8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T04:19:38.689100Z",
     "iopub.status.busy": "2023-07-24T04:19:38.688470Z",
     "iopub.status.idle": "2023-07-24T04:20:24.136093Z",
     "shell.execute_reply": "2023-07-24T04:20:24.135536Z",
     "shell.execute_reply.started": "2023-07-24T04:19:38.689075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14028\n",
      "Accuracy: 0.7859281437125748\n",
      "Execution time: 45.4\n",
      "Samples per second: 308\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = test_tokenized.num_rows\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "\n",
    "    data = test_tokenized[0 + i*batch_size: 0 + i*batch_size + batch_size]\n",
    "    input_np: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")\n",
    "\n",
    "    onnx_output = onnx_model_fp16.run(\n",
    "        None,\n",
    "        input_np,\n",
    "    )\n",
    "    \n",
    "    preds=onnx_output[0].argmax(-1)\n",
    "    labels = np.array(data['label'])\n",
    "    correct+=np.sum(preds==labels)\n",
    "    total+=labels.shape[0]\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Samples: {n_samples}\") \n",
    "print(f\"Accuracy: {correct/total}\")\n",
    "print(f\"Execution time: {round(execution_time, 1)}\")\n",
    "print(f\"Samples per second: {math.floor(n_samples / execution_time)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
